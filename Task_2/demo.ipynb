{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup and Imports: Import necessary libraries (e.g., cv2, matplotlib, numpy, pickle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We downloaded two data packages from the [copernicus](https://browser.dataspace.copernicus.eu/) for August and November. The data contained satellite images of the Kaniv reservoir, from which we selected files B02: Blue band, B03: Green band, B04: Red band."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2024_august\n",
    "2024_november\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Converted the uploaded photos in jp2 format to png format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jp2_to_png(fp_in,fp_out,prefix):\n",
    "    bandList = [band for band in os.listdir(fp_in) if band.endswith('.jp2')]\n",
    "\n",
    "    for band in bandList:\n",
    "        jp2_path = os.path.join(fp_in, band)  # Full path for the input JP2 file\n",
    "        in_image = gdal.Open(jp2_path)\n",
    "        \n",
    "        if in_image is None:\n",
    "            print(f\"Failed to open {jp2_path}\")\n",
    "            continue\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        if driver is None:\n",
    "            print(\"GTiff driver not available\")\n",
    "            continue\n",
    "        \n",
    "        fp_tif = os.path.join(fp_in, band[:-4] + '.tif')  # Output path for the GeoTIFF\n",
    "        \n",
    "        if os.path.exists(fp_tif):# Check if output file already exists\n",
    "            print(f\"File {fp_tif} already exists, skipping.\")\n",
    "            continue\n",
    "        out_image = driver.CreateCopy(fp_tif, in_image, 0) # Create the output image as a GeoTIFF\n",
    "       \n",
    "        if out_image is None:\n",
    "            print(f\"Failed to create {fp_tif}\")\n",
    "\n",
    "        in_image = None\n",
    "        out_image = None\n",
    "        \n",
    "    fp_in = prefix\n",
    "    band_02 = rasterio.open(fp_in + \"B02_60m.tif\")\n",
    "    band_03 = rasterio.open(fp_in + \"B03_60m.tif\")\n",
    "    band_04 = rasterio.open(fp_in + \"B04_60m.tif\")\n",
    "\n",
    "    red = band_04.read(1)\n",
    "    green = band_03.read(1)\n",
    "    blue = band_02.read(1)\n",
    "\n",
    "    rgb_composite_raw= np.dstack((red, green, blue))\n",
    "\n",
    "    def normalize(band):\n",
    "        band_min, band_max = (band.min(), band.max())\n",
    "        return ((band-band_min)/((band_max - band_min)))\n",
    "\n",
    "    red_n = normalize(red)\n",
    "    green_n = normalize(green)\n",
    "    blue_n = normalize(blue)\n",
    "\n",
    "    rgb_composite_n= np.dstack((red_n, green_n, blue_n))\n",
    "\n",
    "    def brighten(band):\n",
    "        alpha=0.13\n",
    "        beta=0\n",
    "        return np.clip(alpha*band+beta, 0,255)\n",
    "\n",
    "    red_b=brighten(red)\n",
    "    blue_b=brighten(blue)\n",
    "    green_b=brighten(green)\n",
    "\n",
    "    red_bn = normalize(red_b)\n",
    "    green_bn = normalize(green_b)\n",
    "    blue_bn = normalize(blue_b)\n",
    "\n",
    "    rgb_composite_bn= np.dstack((red_bn, green_bn, blue_bn))\n",
    "\n",
    "\n",
    "    rgb_plot=plt.imshow(rgb_composite_bn, interpolation='lanczos')\n",
    "    plt.axis('off')\n",
    "    image_path = os.path.join(fp_out,'november.png')\n",
    "    plt.savefig(image_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "    \n",
    "\n",
    "prefix = \"2024_november\\T36UUA_20241107T090059_\"\n",
    "fp_out = \"2024_november_png\"\n",
    "fp_in = \"2024_november\"\n",
    "img_1 = jp2_to_png(fp_in,fp_out,prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt data](./2024_august_png/august.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt data](./2024_november_png/november.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img1_path = \"c:/Users/kybav/OneDrive/Desktop/Home_Work/Home_work_5/Intership_test/Intership_test/Task_2/2024_august_png/august.png\"\n",
    "img2_path = \"c:/Users/kybav/OneDrive/Desktop/Home_Work/Home_work_5/Intership_test/Intership_test/Task_2/2024_november_png/november.png\"\n",
    "\n",
    "img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Verify that images loaded correctly\n",
    "if img1 is None:\n",
    "    print(f\"Error: Could not load image at {img1_path}\")\n",
    "if img2 is None:\n",
    "    print(f\"Error: Could not load image at {img2_path}\")\n",
    "\n",
    "# Proceed only if images are loaded\n",
    "if img1 is not None and img2 is not None:\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Save the model (keypoints and descriptors)\n",
    "    keypoints1 = [\n",
    "        (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) for kp in kp1\n",
    "    ]\n",
    "    keypoints2 = [\n",
    "        (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) for kp in kp2\n",
    "    ]\n",
    "    model_data = {\n",
    "        \"keypoints1\": keypoints1,\n",
    "        \"descriptors1\": des1,\n",
    "        \"keypoints2\": keypoints2,\n",
    "        \"descriptors2\": des2,\n",
    "    }\n",
    "\n",
    "    with open(\"sift_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    print(\"Model saved as sift_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Detection and Matching: Code to detect features, compute descriptors, and match keypoints between the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = \"2024_august_png/august.png\"  # Load images\n",
    "img2_path = \"2024_november_png/november.png\"\n",
    "\n",
    "img1 = cv2.imread(img1_path)\n",
    "img2 = cv2.imread(img2_path)\n",
    "\n",
    "if img1 is None:\n",
    "    print(f\"Error loading {img1_path}\")  # Check if images loaded correctly\n",
    "if img2 is None:\n",
    "    print(f\"Error loading {img2_path}\")\n",
    "\n",
    "if img1 is not None and img2 is not None:\n",
    "    with open(\"sift_model.pkl\", \"rb\") as f:  # Load the model\n",
    "        model_data = pickle.load(f)\n",
    "\n",
    "    kp1 = [\n",
    "        cv2.KeyPoint(\n",
    "            x=pt[0][0],\n",
    "            y=pt[0][1],\n",
    "            _size=pt[1],\n",
    "            _angle=pt[2],  # Reconstruct the keypoints\n",
    "            _response=pt[3],\n",
    "            _octave=pt[4],\n",
    "            _class_id=pt[5],\n",
    "        )\n",
    "        for pt in model_data[\"keypoints1\"]\n",
    "    ]\n",
    "    kp2 = [\n",
    "        cv2.KeyPoint(\n",
    "            x=pt[0][0],\n",
    "            y=pt[0][1],\n",
    "            _size=pt[1],\n",
    "            _angle=pt[2],\n",
    "            _response=pt[3],\n",
    "            _octave=pt[4],\n",
    "            _class_id=pt[5],\n",
    "        )\n",
    "        for pt in model_data[\"keypoints2\"]\n",
    "    ]\n",
    "\n",
    "    des1 = model_data[\"descriptors1\"]  # Load descriptors\n",
    "    des2 = model_data[\"descriptors2\"]\n",
    "\n",
    "    bf = cv2.BFMatcher()  # Matching descriptors\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append([m])\n",
    "    # Draw matches on the images\n",
    "    img3 = cv2.drawMatchesKnn(\n",
    "        img1,\n",
    "        kp1,\n",
    "        img2,\n",
    "        kp2,\n",
    "        good,\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    )\n",
    "\n",
    "    output_path = \"output_matches.png\"  # Save the output image with matches to the specified directory\n",
    "    cv2.imwrite(output_path, img3)  # Save the image in BGR format (OpenCV's default)\n",
    "\n",
    "    plt.figure(\n",
    "        figsize=(12, 6)\n",
    "    )  # Optionally, display the image using Matplotlib, converting BGR to RGB for correct display\n",
    "    plt.imshow(\n",
    "        cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "    )  # Convert BGR to RGB for correct colors\n",
    "    plt.axis(\"off\")  # Hide axis\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt data](./output_matches.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your latest image with matches displayed, you can see two photos (for example, one from August and one from November) with keypoints highlighted and connected by lines. These lines indicate matches (correspondences) between objects in both images, identified through the SIFT (Scale-Invariant Feature Transform) algorithm or another feature detection method.\n",
    "\n",
    "Meaning of the lines: The lines connect points that have a similar structure or texture in both images, showing that the algorithm found these areas to be similar.\n",
    "\n",
    "Importance of these matches: Matches are useful for tasks like comparing changes in terrain, aligning images for further analysis, or detecting seasonal differences (fall vs. summer). They’re also used in 3D model construction, merging seasonal images, or even geodetic studies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
